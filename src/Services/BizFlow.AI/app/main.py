from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware  # <--- [M·ªöI] Import th∆∞ vi·ªán CORS
from pydantic import BaseModel
from typing import List, Any, Optional
import os
import google.generativeai as genai

# Import service
from app.services.stt_service import transcribe_audio
from app.services.nlp_service import extract_order_info
from app.services.rag_service import rag_client

app = FastAPI(title="BizFlow AI Service", version="1.0.0")

# --- [M·ªöI] C·∫§U H√åNH CORS (B·∫ÆT BU·ªòC CHO MOBILE APP) ---
# Cho ph√©p m·ªçi ngu·ªìn (Mobile, Web Admin) g·ªçi v√†o API n√†y
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Cho ph√©p t·∫•t c·∫£ (Demo th√¨ ƒë·ªÉ * cho ti·ªán)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- MODEL RESPONSE (ƒê√£ chu·∫©n h√≥a theo Mobile App c·ªßa Person C) ---
class DraftOrderResponse(BaseModel):
    success: bool
    message: str
    data: Any 

@app.on_event("startup")
async def startup_event():
    # Ki·ªÉm tra v√† c·∫•u h√¨nh Gemini
    try:
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            print("‚úÖ Gemini API Key configured successfully")
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: Gemini configuration failed: {e}")

@app.get("/")
def health_check():
    chroma_status = rag_client.check_health()
    return {"service": "AI Service Ready", "chroma_connected": chroma_status is not None}

@app.post("/api/ai/analyze-voice", response_model=DraftOrderResponse)
async def analyze_voice(file: UploadFile = File(...)):
    # 1. Validation
    if not file.filename.lower().endswith(('.wav', '.mp3', '.m4a', '.ogg', '.aac')):
         # Mobile Flutter th∆∞·ªùng g·ª≠i file .m4a ho·∫∑c .aac
        return DraftOrderResponse(success=False, message="ƒê·ªãnh d·∫°ng file kh√¥ng h·ªó tr·ª£", data=None)

    # 2. ƒê·ªçc file
    file_bytes = await file.read()
    
    # 3. Speech-to-Text
    text_result = await transcribe_audio(file_bytes, file.filename)
    if not text_result:
        return DraftOrderResponse(success=False, message="Kh√¥ng nghe r√µ, vui l√≤ng n√≥i l·∫°i", data=None)
    
    print(f"üì¢ Kh√°ch n√≥i: {text_result}")

    # 4. NLP Extract (L·∫•y intent th√¥)
    draft_order = extract_order_info(text_result)
    
    if not draft_order or not draft_order.get("items"):
         return DraftOrderResponse(success=False, message="Kh√¥ng hi·ªÉu √Ω ƒë·ªãnh mua h√†ng", data=draft_order)

    # 5. RAG: Mapping s·∫£n ph·∫©m v·ªõi Database c·ªßa Person B
    enriched_items = []
    
    for item in draft_order["items"]:
        raw_name = item["product_name"]
        
        # T√¨m ki·∫øm trong ChromaDB
        search_result = rag_client.search_product(raw_name)
        
        if search_result:
            item["product_id"] = int(search_result["id"])
            item["product_name"] = search_result["name"]
            item["price"] = search_result["metadata"]["price"]
            item["image_url"] = search_result["metadata"].get("image", "")
            
            item["total_price"] = item["quantity"] * search_result["metadata"]["price"]
            print(f"‚úÖ Mapped: '{raw_name}' -> ID: {search_result['id']}")
        else:
            # Khi r∆°i v√†o ƒë√¢y nghƒ©a l√† s·∫£n ph·∫©m kh√¥ng c√≥ trong DB ho·∫∑c b·ªã filter do sai l·ªách qu√° l·ªõn
            item["product_id"] = None
            item["price"] = 0
            item["total_price"] = 0
            item["note"] = "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†y trong kho VLXD"
            print(f"‚ùå Not found/Ignored: '{raw_name}'")
            
        enriched_items.append(item)

    draft_order["items"] = enriched_items
    draft_order["raw_text_spoken"] = text_result

    return DraftOrderResponse(
        success=True,
        message="ƒê√£ x·ª≠ l√Ω xong y√™u c·∫ßu",
        data=draft_order
    )